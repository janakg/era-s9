{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/janakg/era-s5/blob/main/S5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PlbomWY3RSq"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Define the repository and the target directory\n",
    "# repo_url = 'https://github.com/janakg/era-s9.git'\n",
    "# target_dir = '/content/era-s9'\n",
    "\n",
    "# # Check if the directory already exists\n",
    "# if not os.path.exists(target_dir):\n",
    "#     # If it doesn't exist, clone the repo\n",
    "#     !git clone {repo_url}\n",
    "# else:\n",
    "#     # If it exists, 'cd' into the directory and pull the latest changes\n",
    "#     %cd {target_dir}\n",
    "#     !git pull\n",
    "\n",
    "# # Add the repository's directory to the system path\n",
    "# import sys\n",
    "# sys.path.append(target_dir)\n",
    "\n",
    "# Import all utils functions\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94BxVVBP3WwS",
    "outputId": "46605080-bcaa-4042-8b60-2b0aec71a6b4"
   },
   "outputs": [],
   "source": [
    "# CUDA?\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(\"CUDA Available?\", use_cuda)\n",
    "\n",
    "\n",
    "# For reproducibility. SEED Random functions\n",
    "SEED = 1\n",
    "torch.manual_seed(SEED)\n",
    "if use_cuda:\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.247, 0.243, 0.261]\n",
    "\n",
    "train_transforms = A.Compose([\n",
    "    A.RandomCrop(32, 32, p=1.0),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=15, p=0.9),\n",
    "    A.CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1, \n",
    "                    min_height=16, min_width=16, fill_value=mean, mask_fill_value=None),\n",
    "    A.Normalize(mean, std),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class AlbumentationsCIFAR10Wrapper(Dataset):\n",
    "    def __init__(self, root='./data', train=True, download=True, transform=None):\n",
    "        self.data = datasets.CIFAR10(root=root, train=train, download=download)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.data[idx]\n",
    "        img = np.array(img)  # PIL Image to numpy array\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpshQ2Ug38m2"
   },
   "outputs": [],
   "source": [
    "# Train Phase transformations\n",
    "# train_transforms = transforms.Compose([\n",
    "#                                       #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "#                                        transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "#                                        transforms.RandomHorizontalFlip(),\n",
    "#                                        transforms.RandomRotation(15),\n",
    "#                                        transforms.ToTensor(),\n",
    "#                                        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # The mean and std have to be sequences (e.g., tuples), therefore you should add a comma after the values. \n",
    "#                                        ])\n",
    "\n",
    "# Test Phase transformations\n",
    "test_transforms = transforms.Compose([\n",
    "                                      #  transforms.ColorJitter(brightness=0.10, contrast=0.1, saturation=0.10, hue=0.1),\n",
    "                                       transforms.ToTensor(),\n",
    "                                       transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                       ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JB79ZYW13-AO",
    "outputId": "f375e7e7-b967-4ca5-cfad-a816b8f58a8a"
   },
   "outputs": [],
   "source": [
    "train_data = AlbumentationsCIFAR10Wrapper(root='./data', train=True, \n",
    "                                          download=True, transform=train_transforms)\n",
    "\n",
    "test_data = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avCKK1uL4A68"
   },
   "outputs": [],
   "source": [
    "# dataloader arguments - something you'll fetch these from cmdprmt\n",
    "dataloader_args = dict(shuffle=True, batch_size=512, num_workers=4, pin_memory=True) if use_cuda else dict(shuffle=True, batch_size=64)\n",
    "\n",
    "# train dataloader\n",
    "train_loader = torch.utils.data.DataLoader(train_data, **dataloader_args)\n",
    "\n",
    "# test dataloader\n",
    "test_loader = torch.utils.data.DataLoader(test_data, **dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "Hx7QkLcw4Epc",
    "outputId": "f300f2b7-1a0a-4a67-d541-fe8b9c525b86"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "import torchvision\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4]))\n",
    "# print labels\n",
    "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))\n",
    "\n",
    "# # Call the util function to show a batch of images\n",
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure()\n",
    "# show_batch_images(plt, train_loader, 12, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UHBolvMH4F8y"
   },
   "outputs": [],
   "source": [
    "# model imported from a module\n",
    "from model import Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "model = Net().to(device)\n",
    "summary(model, input_size=(3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7du4zM474LvT"
   },
   "outputs": [],
   "source": [
    "# Data to plot accuracy and loss graphs\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "\n",
    "test_incorrect_pred = {'images': [], 'ground_truths': [], 'predicted_vals': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Owqiet9M4TV7",
    "outputId": "f5c847c7-642b-4773-becf-70168897809e"
   },
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1, verbose=True)\n",
    "\n",
    "criterion = F.nll_loss\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(1, num_epochs+1):\n",
    "  print(f'Epoch {epoch}')\n",
    "  train_succeeded, train_processed, train_loss = train(model, device, train_loader, optimizer, criterion)\n",
    "  train_acc.append(100 * train_succeeded/train_processed)\n",
    "  train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "  test_succeeded, test_loss = test(model, device, test_loader, criterion)\n",
    "  test_acc.append(100. * test_succeeded / len(test_loader.dataset))\n",
    "  test_losses.append(test_loss)\n",
    "\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "id": "Wu0l7dli4eC9",
    "outputId": "cd1fcdab-0c0f-41dc-d1c9-6b80f9eb7915"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8WZPfXe4iK_"
   },
   "outputs": [],
   "source": [
    "# we will save the conv layer weights in this list\n",
    "model_weights =[]\n",
    "#we will save the 49 conv layers in this list\n",
    "conv_layers = []\n",
    "# get all the model children as list\n",
    "model_children = list(model.children())\n",
    "#counter to keep count of the conv layers\n",
    "counter = 0\n",
    "#append all the conv layers and their respective wights to the list\n",
    "\n",
    "model_children = model.children()\n",
    "for children in model_children:\n",
    "    if type(children) == nn.Sequential:\n",
    "        for child in children:\n",
    "            if type(child) == nn.Conv2d:\n",
    "                counter += 1\n",
    "                model_weights.append(child.weight)\n",
    "                conv_layers.append(child)\n",
    "\n",
    "print(f\"Total convolution layers: {counter}\")\n",
    "print(\"conv_layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "imshow(torchvision.utils.make_grid(images[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = images[9]\n",
    "imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image.unsqueeze(0)\n",
    "image = image.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "names = []\n",
    "for layer in conv_layers[0:]:\n",
    "    image = layer(image)\n",
    "    outputs.append(image)\n",
    "    names.append(str(layer))\n",
    "print(len(outputs))\n",
    "#print feature_maps\n",
    "for feature_map in outputs:\n",
    "    print(feature_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "for feature_map in outputs:\n",
    "    feature_map = feature_map.squeeze(0)\n",
    "    gray_scale = torch.sum(feature_map,0)\n",
    "    # gray_scale = feature_map[0]\n",
    "    gray_scale = gray_scale / feature_map.shape[0]\n",
    "    processed.append(gray_scale.data.cpu().numpy())\n",
    "for fm in processed:\n",
    "    print(fm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 10))\n",
    "for i in range(len(processed)):\n",
    "    a = fig.add_subplot(5, 4, i+1)\n",
    "    imgplot = plt.imshow(processed[i])\n",
    "    a.axis(\"off\")\n",
    "    a.set_title(names[i].split('(')[0], fontsize=10)\n",
    "plt.savefig(str('feature_maps.jpg'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first conv layer filters\n",
    "plt.figure(figsize=(5, 4))\n",
    "first_layer_weights = model_weights[0].cpu()\n",
    "for i, filter in enumerate(first_layer_weights):\n",
    "    plt.subplot(8, 8, i+1) # (8, 8) because in conv0 we have 7x7 filters and total of 64 (see printed shapes)\n",
    "    plt.imshow(filter[0, :, :].detach(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-13.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-13:m109"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
